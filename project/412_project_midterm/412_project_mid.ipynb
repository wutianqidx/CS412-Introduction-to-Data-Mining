{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, Imputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Train Model\n",
    "\n",
    "1. Preprocess data with imputer, scaler, label encoder and polynomial transformer\n",
    "2. Fit logistic regression model on training dataset after 0.8/0.2 train test split and check score\n",
    "3. Fit model on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.33338014 -0.39777496 ...,  0.          0.          0.        ]\n",
      " [ 1.          0.59460177 -1.41365327 ...,  0.          0.          0.        ]\n",
      " [ 1.         -0.89016929  0.3055254  ...,  0.          0.          1.        ]\n",
      " ..., \n",
      " [ 1.         -0.14778376  1.08697025 ...,  0.          0.          1.        ]\n",
      " [ 1.         -0.33338014 -0.00705254 ...,  0.          0.          0.        ]\n",
      " [ 1.         -0.33338014 -0.00705254 ...,  0.          0.          0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46074999999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'training.csv'\n",
    "ins = pd.read_csv(file)\n",
    "\n",
    "# drop columns with NaN% > 0.25\n",
    "n = len(ins['Id'])\n",
    "ins = ins.dropna(thresh = 0.75 * n, axis = 1)\n",
    "\n",
    "# divide features\n",
    "nom_str = 'Product_Info_1, Product_Info_2, Product_Info_3, Product_Info_5, Product_Info_6, Product_Info_7, Employment_Info_2, Employment_Info_3, Employment_Info_5, InsuredInfo_1, InsuredInfo_2, InsuredInfo_3, InsuredInfo_4, InsuredInfo_5, InsuredInfo_6, InsuredInfo_7, Insurance_History_1, Insurance_History_2, Insurance_History_3, Insurance_History_4, Insurance_History_7, Insurance_History_8, Insurance_History_9, Family_Hist_1, Medical_History_2, Medical_History_3, Medical_History_4, Medical_History_5, Medical_History_6, Medical_History_7, Medical_History_8, Medical_History_9, Medical_History_11, Medical_History_12, Medical_History_13, Medical_History_14, Medical_History_16, Medical_History_17, Medical_History_18, Medical_History_19, Medical_History_20, Medical_History_21, Medical_History_22, Medical_History_23, Medical_History_25, Medical_History_26, Medical_History_27, Medical_History_28, Medical_History_29, Medical_History_30, Medical_History_31, Medical_History_33, Medical_History_34, Medical_History_35, Medical_History_36, Medical_History_37, Medical_History_38, Medical_History_39, Medical_History_40, Medical_History_41'\n",
    "num_str = 'Product_Info_4, Ins_Age, Ht, Wt, BMI, Employment_Info_1, Employment_Info_4, Employment_Info_6, Insurance_History_5, Family_Hist_2, Family_Hist_3, Family_Hist_4, Family_Hist_5'\n",
    "dis_str = 'Medical_History_1, Medical_History_10, Medical_History_15, Medical_History_24, Medical_History_32'\n",
    "\n",
    "res = ['Response']\n",
    "num = [x for x in num_str.strip().split(', ') + dis_str.strip().split(', ') \n",
    "       if x in ins.columns.values]\n",
    "cat = [x for x in nom_str.strip().split(', ') + ['Medical_Keyword_%s' % i for i in range(1, 49)] \n",
    "       if x in ins.columns.values]\n",
    "\n",
    "# generate imputer, scaler, encoder and polynomial transformer \n",
    "imputer = Imputer(strategy = 'median')\n",
    "imputer.fit(ins[num])\n",
    "scaler = StandardScaler()\n",
    "pf = PolynomialFeatures(degree = 3)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(ins['Product_Info_2'].astype(str))\n",
    "\n",
    "# Define preprocessing functions\n",
    "def get_keep_col(df, res = 'Response', corr = 0.15):\n",
    "    corr_matrix = df.corr()[res]\n",
    "    keep_col = [col for col in df.columns.values if abs(corr_matrix[col]) >= corr and col != res]\n",
    "    return keep_col\n",
    "\n",
    "def preprocess(df, num = num, cat = cat, imputer = imputer, encoder = encoder):\n",
    "    tr = imputer.transform(df[num])\n",
    "    df[num] = pd.DataFrame(tr, columns = df[num].columns)\n",
    "    df['Product_Info_2'] = encoder.transform(df['Product_Info_2'].astype(str))\n",
    "    df[cat] = df[cat].fillna(-1)\n",
    "    return df\n",
    "\n",
    "def generate_train_data(df, pf = pf, scaler = scaler, num = num, cat = cat):\n",
    "    df = preprocess(df)\n",
    "    df[num] = scaler.fit_transform(df[num])\n",
    "    keep_col = get_keep_col(df)\n",
    "    X = df[keep_col]\n",
    "    X_df = X.copy()\n",
    "    X = pf.fit_transform(X)\n",
    "    return X, keep_col, scaler, X_df\n",
    "\n",
    "X, keep_col, scaler, X_df = generate_train_data(ins)\n",
    "print(X)\n",
    "y = ins['Response']\n",
    "\n",
    "# Perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
    "\n",
    "def fit_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score, y_pred\n",
    "\n",
    "# Fit RandomForestClassifier\n",
    "rfc = AdaBoostClassifier(random_state = 0)\n",
    "rfc_score, rfc_y = fit_model(rfc, X_train, X_test, np.ravel(y_train), y_test)\n",
    "rfc.fit(X, y)\n",
    "\n",
    "rfc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "[ 0.          0.33333333  0.          0.          0.33333333  0.          0.\n",
      "  0.          0.          0.          0.33333333  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.33333333  0.33333333  0.          0.          0.          0.33333333\n",
      "  0.33333333  0.          0.          0.          0.33333333  0.33333333\n",
      "  0.33333333  0.          0.          0.          0.33333333  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.33333333  0.          0.          0.          0.33333333  0.          0.\n",
      "  0.          0.          0.33333333  0.33333333  0.          0.          0.\n",
      "  0.33333333  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.33333333  0.\n",
      "  0.33333333  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.33333333  0.          0.\n",
      "  0.33333333  0.          0.          0.          0.33333333  0.33333333\n",
      "  0.          0.33333333  0.33333333  0.          0.33333333  0.          0.\n",
      "  0.33333333  0.33333333  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.66666667  0.          0.66666667\n",
      "  0.          0.          0.33333333  0.          0.          0.33333333\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          1.\n",
      "  0.66666667  0.33333333  0.33333333  0.          0.          1.\n",
      "  0.33333333  0.          0.66666667  0.33333333  0.          0.          0.\n",
      "  0.33333333  0.66666667  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]))\n",
    "\n",
    "fi = rfc.feature_importances_ / np.max(rfc.feature_importances_)\n",
    "# Display name and importance\n",
    "print(fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test Data\n",
    "1. Preprocess test data same as previous section\n",
    "2. Predict response with model and generate output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testfile = 'testing.csv'\n",
    "test = pd.read_csv(testfile)\n",
    "\n",
    "def adjust_columns(testX, X = X_df):\n",
    "    extra_col = [x for x in testX.columns.values if x not in X.columns.values]\n",
    "    lack_col = [x for x in X.columns.values if x not in testX.columns.values]\n",
    "    df = testX.drop(extra_col, axis = 1)\n",
    "    for x in lack_col:\n",
    "        df[x] = 0\n",
    "    return df\n",
    "\n",
    "def generate_test_data(df, pf = pf, cat = cat, keep_col = keep_col, scaler = scaler):\n",
    "    df = preprocess(df)\n",
    "    df[num] = scaler.transform(df[num])\n",
    "    X = df[keep_col]\n",
    "    X = adjust_columns(X)\n",
    "    X = pf.transform(X)\n",
    "    return X\n",
    "\n",
    "testX = generate_test_data(test)\n",
    "y_pred = rfc.predict(testX)\n",
    "\n",
    "Id = pd.DataFrame(test['Id'], columns = ['Id'])\n",
    "response = pd.DataFrame(y_pred, columns = ['Response'], dtype = str)\n",
    "\n",
    "result = pd.concat([Id, response], axis = 1)\n",
    "result.to_csv('solution.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
